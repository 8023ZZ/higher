### MySql
MySql 是关系型数据库，默认端口号是 3306

### 存储引擎
默认存储引擎是 InnoDB，并且只有 InnoDB 可以支持事务

#### MyISAM 和 InnoDB 的区别
MyISAM 是 MySql 在5.5版本以前的默认存储引擎，虽然性能极佳，而且提供了大量的特性，包括全文索引，压缩和空间函数等，但 MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。5.5版本之后默认存储引擎更改为 InnoDB

MyISAM 在读密集的情况下可以使用

两者的对比：
1. 是否支持行级锁： MyISAM 只支持表级锁，而 InnoDB 支持行级锁和表级锁，默认为表级锁
2. 是否支持事务和崩溃后安全恢复：MyISAM 强调的是性能，每次查询具有原子性，其执行速度比 InnoDB 更快，但是不提供事务支持，但是 InnoDB 提供事务支持，外部键等高级数据库表功能。具有事务，回滚和崩溃修复能力的事务安全型表
3. 是否支持外键：MyISAM 不支持，而 InnoDB 支持
4. 是否支持 MVCC：仅 InnoDB 支持，应对高并发事务，MVCC 比单纯的加锁更高效；MVCC 只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下功能；MVCC 可以使用乐观锁和悲观锁来实现；各数据库中 MVCC 实现并不统一
   
很多已知场景中，InnoDB 的速度都可以让 MyISAM 望尘莫及，尤其是用到了聚集索引，或者需要访问的数据都可以放入内存的应用

### 字符集及校对规则
字符集指的是一种从二进制编码到某类字符符号的映射，校对规则是指某种字符集下的排序规则。MySql 每一种字符集都会对应一系列的校对规则

### 链接池
MySql 中的连接池是维护与系统之间的多个数据库连接，除此之外，每次跟 MySql 建立连接时，还会根据传输过来的账号和密码，进行账号密码的验证，库表权限的验证

### 结构
SQL 解析器解析 SQL 语句 -> 查询优化器选择最优查询路径 -> 执行器根据执行计划不停地调用存储引擎接口去完成 SQL 的执行计划 -> 调用存储引擎接口，执行 SQL 语句，存储引擎会按照一定的步骤去查询内存缓存数据、更新磁盘数据、查询磁盘数据等

### 存储引擎 InnoDB
InnoDB 有一个非常重要的放在内存中的组件：缓冲池

执行阶段：查询时会先查询缓冲池，如果不在会查询磁盘并放入缓冲池，并对这行记录加独占锁，然后将更新前的值写入 undo 日志（便于回滚），之后再更新缓冲池中的数据，在缓冲池中记录 Redo 日志（MySql 宕机时用来恢复数据），之后提交事务时将 redo log buffer 刷入磁盘中

提交事务阶段：redo 日志刷盘策略分为 3 种，为 0 时，提交事务不会把 redo log  buffer 里的数据刷入磁盘中，为 1 时，提交事务时会把 redo log 刷入磁盘中，为 2 时，提交事务时会把 redo log 写入磁盘文件对应的 os cache 中，可能 1 秒后才会把 os cache 中的数据写入到磁盘文件中

bin log 归档日志不是 InnoDB 特有的，而是属于 Mysql Server 自己的，提交事务的时候会把 bin log 日志写入磁盘中，bin log 刷盘策略分为 2 中，为 0 时，写入 os cache 内存缓存；为 1 时，提交事务时直接刷入磁盘文件

当把 bin log 写入磁盘文件之后，会把本次更新对应的 bin log 文件名称和这次更新的 bin log 在文件里的位置都写入到 redo log 中，同时在 redo log 中写入一个 commit 标记，完成之后才最终完成事务的提交，commit 标记用来保证 redo log 和 bin log 完全一致

MySql 后台 IO 线程随机将内存更新后的脏数据刷回磁盘数据文件中

### 服务器配置
4核8G的 Java 应用系统，每秒并发量基本在几百左右。

数据库服务器通常是8核16G或者16核32G，16核32G的机器部署的 Mysql 数据库每秒并发请求可以在三四千

### Buffer Pool
数据页，MySql 对数据抽象出一个数据页的概念，他把很多行数据放到一个页中，更新一行数据时，数据库会先找到这行数据所在的数据页，然后从磁盘文件中把这行数据所在的数据页直接加载到 buffer pool 中

默认情况下，buffer pool 中的缓存页和磁盘中的数据页大小是一一对应的，都是16 KB

每个缓存页都有一个描述信息，包含缓存页所属的表空间、数据页编号、缓存页在缓存池中的地址等信息，描述信息本身也是一块数据，放在 buffer pool 中，描述信息大概相当于缓存页大小的 5% 左右，buffer poll 的 size 仅包含缓存页的大小，不包含描述信息的大小

数据库启动后，会按照设置的 buffer pool 的大小，稍微再加大一点，去申请内存，申请完毕后，数据库会按照默认的缓存页的 16 KB的大小以及对应的 800 个字节左右的描述数据的大小，在 Buffer Pool 中划分出来一个一个的缓存页和一个一个的他们对应的描述信息

为了得知 Buffer Pool 中哪些缓存页是空闲状态，数据库会为 Buffer Pool 设计一个 free 链表，他是一个双向链表，这个 free 链表每个节点是一个空闲的缓存页的描述数据块信息，只要缓存页是空闲的，那么他的描述数据块就会被放到这个 free 链表中

除此之外，free 链表还有一个头结点和一个尾结点，里面存储了链表中还有多少描述数据块的节点，即还有多少个空闲的缓存页

将磁盘的数据页读取到缓冲池时，先从 free 链表中获取一个描述数据块，然后就可以对应的获取到对应的空闲缓存页，接着就可以把磁盘上的数据页读取到对应的缓存页中，同时把一些描述信息写入到缓存页的描述数据块中，最后把这个描述数据块从 free 链表中除去即可

数据库还会有一个 hash 表数据结构，他会用表空间号+数据页号作为 key，缓存页地址作为 value，用于判断是否需要从磁盘中加载数据页

数据库还会引入一个 flush 链表，本质也是通过缓存页的描述数据块中的两个指针，让被修改的缓存页的描述数据块组成一个双向链表，用于判断缓存页是否为脏页

Buffer Pool 中还有一个 LRU 链表，最近最少使用，我们从磁盘中加载一个数据页到缓存页时，就把这个缓存页的描述数据块放到 LRU 链表头部，最近访问的缓存页信息都会被移动到头部

MySql 有预读机制，他从磁盘中加载数据页时，可能会连同这个数据页相邻的其他数据页都加载到缓存中。预读机制是为了避免大量的磁盘IO

预读机制的触发时机：
* innodb_read_ahead_threshold，默认值是56，如果顺序的访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区的所有数据页都加入缓存中
* innodb_random_read_ahead 来控制开关，如果 Buffer Pool 里缓存了一个区里的13个连续的数据页，而且这些数据页是频繁被访问的，那么就会触发预读机制，把这个区里的其他数据页都加载到缓存中去

LRU 链表会按37开的比例拆分为冷热两个部分，数据页第一次被加载到缓存时，缓存页会被放在冷数据区域的链表头部位置，1s之后如果缓存页被访问，则会被放到热数据区域的链表头部位置

Mysql 定时任务每隔一段时间清空 LRU 冷数据区域的缓存页以及 flush 链表中的缓存页，将它们刷回磁盘，把他们加入回 free 链表，移出 flush 链表和 LRU 链表

多线程操作同一个 Buffer Pool 的时候需要加锁，因此可以分配多个 Buffer Poll 来提升性能

Mysql 中有 chunk 机制，每个 buffer pool 由一系列 128M 的 chunk 组成，这些 chunk 共享一个 buffer pool 的 free、flush、lru 这些链表，通过 chunk 机制可以在运行时动态调整 buffer pool 的大小

### 磁盘
变长字段长度（16进制逆序排列）+null 值列（每个bit表示是否为null）+数据头（40bit）+实际数据值

数据头记录本行记录的一些类型以及下一行数据的指针

然后根据字符集编码，转换成一些数字和符号存储在磁盘上，同时会在实际数据值的部分中增加DB_ROW_ID（行唯一标识），DB_TRX_ID(事务ID)，DB_ROLL_PTR(回滚指针)

而一个数据页被拆成了很多部分，包含了文件头、数据页头、最小记录和最大记录、多个数据行、空闲空间、数据页目录、文件尾部，数据页包含了指向上一个数据页的指针和指向下一个数据页的指针，构成了双向链表。然后数据页里的每一行数据都会按照主键的大小进行排序，每一行数据都有指向下一行的指针，组成了单向链表

一个表空间对应着一些磁盘上的数据文件，这些磁盘上的数据文件中有很多的数据页

一个数据区对应着连续64个数据页，每个数据页是16KB，一个数据区是1M，256个数据区被划分为一组，每个表空间的第一个组数据区的第一个数据区的前三个数据页都是固定的，存放一些描述性数据。当我们需要执行 curd 操作的时候，说白了就是从磁盘上的表空间的数据文件里，随机访问去加载一些数据页到 Buffer Pool 的缓存页使用

redo log写入是磁盘顺序写，几乎和内存随机读写的性能差不多，redo log 写的越快，sql 语句的性能就越高

### 行溢出
当一行的数据大于数据页大小16KB时，会发生行溢出，溢出的数据会放到其他的数据页当中

### RAID 存储架构
RAID 就是一个磁盘冗余阵列，大致理解为用来管理机器的多块磁盘的一种磁盘阵列技术

RAID 还可以实现数据冗余机制，写入同样一份数据，会在两块磁盘上都写入

但是 RAID 锂电池自动充放电会导致数据库服务器 RAID 存储性能出现几十倍的抖动

### Redo Log
redo log 的日志格式大致为：对表空间XXX的数据页XXX中的偏移量为XXX的地方更新了数据XXX

表空间+数据页号+偏移量+修改几个字段的值+具体的值

redo log 不是单行写入日志文件的，而是通过 redo log block 来存放多个单行日志，redo log block 分为三部分：header（12字节）、body（496字节）、trailer（4字节）

header 可以继续细分：block no（4字节的块唯一编号）、data length（2个字节的已写入数据长度）、first record group（2字节的日志分组偏移量）、checkpoint on（4字节）

每一个redo log 都是写入到redo log磁盘文件里的一个 redo log block里去了，每个redo log block最多放496KB的redo log日志

redo log buffer 是Mysql 启动时向操作系统申请的一段连续的内存空间，里面划分了 n 个redo log block，默认为 16MB 大小，如果所有的 redo log block 全部写满，则会强制把 redo log block 刷入磁盘

一个事务中的所有redo log会等待sql全部执行完成后才会一起写入 redo log block

redo log block 输入磁盘的时机：

1. 如果写入redo log buffer 的日志已经占据了redo log buffer 空间的一半，此时会把他们刷入磁盘空间中

2. 一个事务提交的时候，必须把他的redo log 所在的 redo log block 都刷入到磁盘文件当中，需要设置参数

3. 后台线程定时刷新，有一个线程每隔1s就会把redo log buffer 中的redo log block刷到磁盘文件当中

4. Mysql 关闭的时候，redo log block都会刷入磁盘当中

磁盘中默认会有两个 redo log 文件，写入满后会覆盖另一个文件

### Undo log
这条日志的开始位置+主键的各列长度和值+表id+undo log日志编号+undo log日志类型+这条日志的结束位置

每个事务里的 undo log 编号都是从0开始，然后依次递增

### 事务隔离级别
脏读、不可重复度、幻读

读未提交（不可能在两个事务未提交的情况下更新同一行数据的值）、读提交、可重复读（事务执行期间多次读一行数据的值不变）、串行化

原因是因为数据库并发执行多个事务，每个线程可能都会开启一个事务，多个事务可能会并发的对缓存页里的同一批数据进行增删改查操作

MySql 默认事务隔离级别是读提交，且 Mysql 的读提交和 Sql 标准的 RR 级别不同，Mysql 的 RR 级别避免了幻读

### MVCC
mvcc 用来解决脏读、不可重复读、幻读的问题

Mysql 通过 MVCC 多版本并发控制机制实现事务隔离，MVCC 是通过 undo log 版本链 + ReadView 机制实现的

Mysql 每条数据都有两个隐藏字段，一个是 trx_id，是最近一次更新这条数据的事务id，另一个是 roll_pointer，指向更新事务之前生成的 undo log。多个事务并发的时候都会更新隐藏字段，同时之前多个数据快照对应的 undo log 会通过 roll_pointer 串联起来，形成一个重要的版本链

执行事务时，Mysql 会生成一个 ReadView，包含四部分内容：
* m_ids，事务活跃列表，代表此时有哪些事务在 Mysql 中执行还没提交的
* min_trx_id，就是m_ids里的最小的值
* max_trx_id，就是 Mysql 下一个要生成的事务ID，就是最大事务 ID
* creator_trx_id，就是本事务的id
  
通过 ReadView 来判断读取的数据内容的版本，事务自身修改的数据或者在生成 ReadView 之前就已提交的事务修改的数据是可以读取到的，而其他情况下的事务提交之后是读不到的

RC隔离级别：设置每次发起查询，都重新生成一个 ReadView，判断要读取得数据行的事务id 是否在m_ids内，如果在就根据 roll_pointer 查找最近一个不在 m_ids 内的undo log ，然后获取值

RR隔离级别：只在第一次开启查询时创建 ReadView，之后查询都不会创建 ReadView

### 锁机制
锁机制用来解决脏写的问题

多个事务同时更新同一行数据，此时都会加锁等待，必须一个事务执行完毕并提交释放锁后才会唤醒别的事务继续执行。锁用的是 Exclude 独占锁，当有一个事务加了独占锁之后，其他事务如果要更新这行数据，只能生成独占锁后等待

读和写操作不是互斥的，可以同时进行

读写操作会自动加上表级意向锁，表级意向锁彼此之间不会互斥，但是会和表级锁互斥

### 索引
每个数据页会根据行的主键存放一个目录，没有索引的时候，先将第一页数据页加载到 buffer poll 中，然后根据主键和目录遍历链表查找到对应的数据页，然后用二分算法查找到对应的行，没找到则把第二个数据页加载到 buffer pool 中，继续此流程。如果用非主键字段查找，则只能一行一行遍历查询。

页分裂，主键值不是递增的情况下会发生，来保证新的数据页的主键值都比上一个数据页的主键值大

主键索引：把每个数据页的页号还有数据页最小的主键值放在一起，组成一个索引的目录，可以通过二分法去直接查找主键对应数据行的数据页位置，然后再二分查找对应的数据行。这个主键索引是一个B+树，这个B+树只记录它的下一层的索引页的最小主键和索引页的页号，叶子节点的索引页记录了数据页页号和对应的最小的主键值。同一级的索引页之间也构成了双向链表，而叶子节点的索引页和他记录的数据页之间也指针指向数据页。因此在这棵B+树中，真正的叶子节点是数据页

聚簇索引：如果一颗大的B+树索引结构里，叶子节点是数据页本身，那么此时我们可以称这颗B+树索引为聚簇索引，通常来说即使是亿级的大表，索引层级也只有三四级

其他字段的索引：插入数据时，一边会自动维护好聚簇索引，另一边会为其他字段建立索引，重新再建一颗B+树，这颗B+树的叶子节点也是数据页，但是这个数据页中仅包含主键字段和索引字段。叶子节点的该索引字段都是按照字段从小到大排列的，中间节点会存放下一层的页号和最小的索引字段值以及主键。查找的时候会根据索引字段查找到对应的主键字段，然后回表。如果是联合索引，那么会按照索引字段最左边的字段进行排序

数据页新建的时候是一个根页，之后数据页满了新增数据页时，根页会升级为索引页，索引页满的时候会新增索引页，且根页会成为上一级索引，根页永远都是B+树的根节点

索引过多会占据过多的空间，且影响增删改的性能，因为需要维护很多索引，但是可以提高读的速度

等值匹配规则：Mysql 自动按照联合索引的字段去进行查找

最左侧列匹配规则：联合索引只能按照最左端的字段开始，从左到右进行查询

最左前缀匹配规则：使用 like '1%' 时可以利用到索引的，但是 like '%1' 不行

范围查找规则：where 语句里如果有范围查询，那只有对联合索引里最左侧的列进行范围查询才能用到索引

等值匹配+范围匹配规则：那么可以用联合索引最左侧的列精准匹配到一批数据，然后用左边第二列进行范围查询，但是左边第三列的范围查询不能利用索引

sql 语句里，尽量按照联合索引的字段顺序去进行 order by 排序，但是需要同时升序或降序

覆盖索引不是一种索引，是基于索引的一种查询方式，需要的字段如果直接在索引树中就可以提取出来，不需要回表到聚簇索引，这种查询方式就是覆盖所引。如果SQL 能够用到联合索引，但是需要回表到聚簇索引的次数太多了，可能就会直接全表扫描不走联合索引了

索引设计原则：
* 根据应用里 SQL 语句里的 where、order by、group by 条件去设计索引
* 建立索引尽量选择值比较多的字段，才能发挥出二分查找的优势
* 尽量不要在查询语句里增加函数或者计算

SQL 里一旦一个字段做范围查询时使用到了索引，那么这个字段接下来的条件都不能使用索引。尽量用一两个复杂的多字段联合索引，抗下80%以上的查询，然后用一两个辅助索引抗下剩余的20% 的查询，保证 99% 的查询都能利用索引。

联合索引建议不超过5个并且索引字段长度不要过长

### 执行计划
id越大越优先执行，相同 id 从上向下执行

const：性能超高的常量级，比如直接通过聚簇索引或者二级索引+聚簇索引回源，但是二级索引必须是唯一索引 unique 才可以

ref：非唯一索引，或者包含多个列的普通索引，从索引最左侧开始连续多个列都是等值比较，还有一个例外，如果是用 is null 这种语法，即使是主键或者唯一索引，还是只能走 ref 方式。

ref_or_null：针对一个二级索引同时比较了一个值还限定了 is null

range：范围查询时会使用

index：遍历二级索引，而不需要回源到聚簇索引

all：全表扫描

在执行 SQL 的时候，也可能会同时查多个索引树然后求交集或者并集

const、ref、range都是性能最好的方式，index是扫描二级索引树，不从根节点开始二是直接遍历子节点

多表关联情况下，会先从驱动表中查出一些数据，然后根据这些数据去被驱动表里查另一波数据进行关联

内连接 on 和 where 判断的结果集是一样的

嵌套循环关联：在驱动表中按where 条件查出数据，然后对每一条数据循环按 where 和 on 条件在被驱动表中查询数据，找出来数据就进行关联

一条 sql 的执行成本一般是两部分，第一部分是将数据从磁盘读到内存的缓存页中的IO成本，读一页的成本约定为1，IO成本就是数据页数*1；第二部分是拿到数据后进行的运算，包括搜索条件、排序分组等一些CPU成本，检测一条数据是否符合的成本约定为0.2，CPU成本就是行数*0.2

执行计划本质就是先访问哪个表，用哪个索引还是全表扫描，拿到数据后如何去聚簇索引回表，是否要基于临时磁盘文件做分组聚合或者排序

当驱动表没有索引时会将驱动表放入 join buffer 中然后遍历查询被驱动表的每一行记录和 join buffer 中驱动表进行比较，否则驱动表每次都需要从磁盘读取一次

in 先进行子查询，而 exist 以外层表为驱动表，另外 in 不对 null 进行处理

如果我们用 group by、order by、union、distinct之类的语法的时候，如果没法直接用索引来分组聚合，那么他们就会基于临时表来完成，也会有大量磁盘操作，性能很低。数据量较小时会使用内存临时表，数据量大时会落地到磁盘上

